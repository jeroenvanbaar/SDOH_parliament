{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08563a49",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e1e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c09c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib, os,sys, pdfplumber, glob, requests, wordcloud, re, dateparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9192c128",
   "metadata": {},
   "source": [
    "# Set up working dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca98c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.realpath('../..')\n",
    "print(base_dir)\n",
    "data_dir = base_dir + '\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e0c7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = data_dir + '\\\\TK_commissieVWS\\\\auto_download_20230118'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143ba07",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vws_data = pd.read_csv(in_dir + '\\\\speaking_turns_coded.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2dc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vws_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc2cde",
   "metadata": {},
   "source": [
    "## Load lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62efe1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex_dict = {'original':pd.read_csv(data_dir + '\\\\lexicons\\\\lexicon.csv',  index_col = 0),\n",
    "            'sens_noSEGV':pd.read_csv(data_dir + '\\\\lexicons\\\\lexicon_no_SEGV.csv', index_col = 0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7dcce5",
   "metadata": {},
   "source": [
    "## Find terms in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0690626",
   "metadata": {},
   "source": [
    "##### apply fun to speaking turns and identify categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9538e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for lex_name,lexicon_use in lex_dict.items():\n",
    "    \n",
    "    all_speaking_turns_labeled = vws_data.copy()\n",
    "    \n",
    "    print(lex_name)\n",
    "    print('Creating category count placeholders')\n",
    "    all_speaking_turns_labeled['lexicon'] = lex_name\n",
    "    all_speaking_turns_labeled['LEEF'] = np.zeros([all_speaking_turns_labeled.shape[0],1])\n",
    "    all_speaking_turns_labeled['SDOH'] = np.zeros([all_speaking_turns_labeled.shape[0],1])\n",
    "\n",
    "    for ci,cat in enumerate(lexicon_use['category'].unique()):\n",
    "\n",
    "        print('Category: %s.'%cat)\n",
    "        cat_lexicon = lexicon_use.loc[lexicon_use['category']==cat,:].copy().reset_index(drop=True)\n",
    "\n",
    "        for ti,term_info in cat_lexicon.iterrows():\n",
    "\n",
    "            # Load term\n",
    "            term = term_info['term']\n",
    "            term_regex =  term_info['regex_search']\n",
    "            print('Term: %s. Pattern: %s.'%(term, term_regex))\n",
    "\n",
    "            turns_with_term_i = (all_speaking_turns_labeled['text'].str.count(term_regex).values > 0).astype(int)\n",
    "            print('%i turns with term found'%sum(turns_with_term_i))\n",
    "\n",
    "            all_speaking_turns_labeled[term] = turns_with_term_i\n",
    "            all_speaking_turns_labeled[cat] = np.maximum(all_speaking_turns_labeled[cat],turns_with_term_i).astype(int)\n",
    "    \n",
    "    # Save\n",
    "    print('total counts:')\n",
    "    print(all_speaking_turns_labeled[['SDOH','LEEF']].sum(axis=0))\n",
    "    print('Saving table with shape %s, %s\\n\\n'%all_speaking_turns_labeled.shape)\n",
    "    all_speaking_turns_labeled.to_csv(in_dir + \n",
    "              '\\\\speaking_turns_coded_labeled-%s.csv'%lex_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
